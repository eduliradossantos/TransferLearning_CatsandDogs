{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "b3webTHLxKhI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "B7UlCl4FF0TR"
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.5\n",
    "RANDOM_STATE = 2018\n",
    "BATCH_SIZE = 64\n",
    "NO_EPOCHS = 10\n",
    "NUM_CLASSES = 2\n",
    "SAMPLE_SIZE = 20000\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dLCYKcl86PyH"
   },
   "outputs": [],
   "source": [
    "PATH = \"/content/drive/MyDrive/Colab Notebooks/\"  # Or your desired path\n",
    "train_image_path = os.path.join(PATH, \"train.zip\")\n",
    "test_image_path = os.path.join(PATH, \"test.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_progress(block_num, block_size, total_size):\n",
    "    downloaded = block_num * block_size\n",
    "    percent = min(100, downloaded * 100 / total_size)\n",
    "    print(f\"\\rBaixando: {percent:.2f}%\", end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5yYpWxewxRa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando download...\n",
      "Baixando: 100.00%\n",
      "Download concluído!\n",
      "Extraindo arquivos...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtraindo arquivos...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(local_zip, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m---> 16\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMAGENS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtração concluída!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\Lib\\zipfile\\__init__.py:1744\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1741\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_member(zipinfo, path, pwd)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\anaconda3\\Lib\\zipfile\\__init__.py:1801\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1797\u001b[0m         os\u001b[38;5;241m.\u001b[39mmkdir(targetpath)\n\u001b[0;32m   1798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[1;32m-> 1801\u001b[0m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[0;32m   1802\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(source, target)\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# URL do dataset\n",
    "url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "local_zip = \"cats-and-dogs.zip\"\n",
    "\n",
    "# Download do arquivo com progresso\n",
    "print(\"Iniciando download...\")\n",
    "urllib.request.urlretrieve(url, local_zip, reporthook=download_progress)\n",
    "print(\"\\nDownload concluído!\")\n",
    "\n",
    "# Criar diretório para extração\n",
    "os.makedirs('IMAGENS', exist_ok=True)\n",
    "\n",
    "# Extração do arquivo ZIP\n",
    "print(\"Extraindo arquivos...\")\n",
    "with zipfile.ZipFile(local_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall('IMAGENS')\n",
    "print(\"Extração concluída!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Exoi9n_xxVYs"
   },
   "outputs": [],
   "source": [
    "root = 'IMAGENS/PetImages'\n",
    "exclude = ['Thumbs.db']\n",
    "corrupted_files = [\n",
    "    os.path.join(root, \"Cat/666.jpg\"),\n",
    "    os.path.join(root, \"Dog/11702.jpg\")\n",
    "]\n",
    "\n",
    "# Remover arquivos corrompidos\n",
    "for file in corrupted_files:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swdR1JDBxhke"
   },
   "outputs": [],
   "source": [
    "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfTGBEO0xjhI"
   },
   "outputs": [],
   "source": [
    "def label_pet_image_one_hot_encoder(img):\n",
    "    pet = img.split('.')[-3]\n",
    "    if pet == 'cat': return [1,0]\n",
    "    elif pet == 'dog': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2Rh2sLMxlmp"
   },
   "outputs": [],
   "source": [
    "def process_data(data_image_list, DATA_FOLDER, isTrain=True):\n",
    "    data_df = [] # Initialize data_df as an empty list\n",
    "    for img in tqdm(data_image_list):\n",
    "        path = os.path.join(DATA_FOLDER,img)\n",
    "        if(isTrain):\n",
    "            label = label_pet_image_one_hot_encoder(img)\n",
    "        else:\n",
    "            label = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Check if the image was loaded successfully\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image at path: {path}\")\n",
    "            continue  # Skip this image if it's not readable\n",
    "\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        data_df.append([np.array(img),np.array(label)])\n",
    "    shuffle(data_df)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8X434FKxmgX"
   },
   "outputs": [],
   "source": [
    "train_image_list = []\n",
    "for folder in ['Cat', 'Dog']:\n",
    "    folder_path = os.path.join(root, folder)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Add any other image extensions if needed\n",
    "            train_image_list.append(os.path.join(folder, filename))  # Store relative paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7T7AVYOUxpwG"
   },
   "outputs": [],
   "source": [
    "def plot_image_list_count(data_image_list):\n",
    "    labels = []\n",
    "    for img in data_image_list:\n",
    "        # Check if the image name has enough parts after splitting\n",
    "        parts = img.split('.')\n",
    "        if len(parts) >= 3:  # Make sure there are at least 3 parts\n",
    "            labels.append(parts[-3])  # Now it's safe to access [-3]\n",
    "    sns.countplot(labels)\n",
    "    plt.title('Cats and Dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17PvNfSExr4m"
   },
   "outputs": [],
   "source": [
    "def label_pet_image_one_hot_encoder(img):\n",
    "    # Split the path using os.path.sep to handle different path separators\n",
    "    parts = img.split(os.path.sep)\n",
    "    # Get the second to last part, which should be 'Cat' or 'Dog'\n",
    "    pet = parts[-2]\n",
    "    if pet == 'Cat':\n",
    "        return [1, 0]\n",
    "    elif pet == 'Dog':\n",
    "        return [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6V4LwIsCxuJP"
   },
   "outputs": [],
   "source": [
    "def show_images(data, isTest=False):\n",
    "    f, ax = plt.subplots(5,5, figsize=(15,15))\n",
    "    for i,data in enumerate(data[:25]):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        label = np.argmax(img_num)\n",
    "        if label  == 1:\n",
    "            str_label='Dog'\n",
    "        elif label == 0:\n",
    "            str_label='Cat'\n",
    "        if(isTest):\n",
    "            str_label=\"None\"\n",
    "        ax[i//5, i%5].imshow(img_data)\n",
    "        ax[i//5, i%5].axis('off')\n",
    "        ax[i//5, i%5].set_title(\"Label: {}\".format(str_label))\n",
    "    plt.show()\n",
    "train = process_data(train_image_list, root)\n",
    "show_images(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbSsJLwn-9n3"
   },
   "outputs": [],
   "source": [
    "# Create a list to store the paths of the test images\n",
    "test_image_list = []\n",
    "\n",
    "# Assuming all images are in the root directory and you want to split them for testing\n",
    "# You can modify this logic based on your actual data structure\n",
    "for folder in ['Cat', 'Dog']:\n",
    "    folder_path = os.path.join(root, folder)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Example: Use a percentage of images for testing (e.g., 20%)\n",
    "            if random.random() < 0.20:  # Adjust the percentage as needed\n",
    "                test_image_list.append(os.path.join(folder, filename))\n",
    "            else:\n",
    "                train_image_list.append(os.path.join(folder, filename))\n",
    "\n",
    "# Now you can call process_data with test_image_list\n",
    "# You may need to adjust isTrain=True if you want to process labels for the test set\n",
    "test = process_data(test_image_list, root, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsxYKBqXAEmR"
   },
   "outputs": [],
   "source": [
    "show_images(test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZXjxLh-AGsA"
   },
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "y = np.array([i[1] for i in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIR4HPGcHNlG"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"Memory growth enabled for GPU: {gpu}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSNgBx7NAJgp"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ResNet50(include_top=False, pooling='max', weights='imagenet'))  # Use 'imagenet' for pre-trained weights\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XOIcV0xAJap"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pegOB4MjFbx7"
   },
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugtKzQVTFiWY"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Z_JpffvGWOv"
   },
   "outputs": [],
   "source": [
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=NO_EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sTToW_eIvKT"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['acc']\n",
    "    val_acc = hist['val_acc']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    f, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "    ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
    "    ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "plot_accuracy_and_loss(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-He1D0bI5zu"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K55D4UMyK4FR"
   },
   "outputs": [],
   "source": [
    "#get the predictions for the test data\n",
    "predicted_classes = model.predict_classes(X_val)\n",
    "#get the indices to be plotted\n",
    "y_true = np.argmax(y_val,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-QtHX2UK7In"
   },
   "outputs": [],
   "source": [
    "correct = np.nonzero(predicted_classes==y_true)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=y_true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okKYrhEaK-av"
   },
   "outputs": [],
   "source": [
    "target_names = [\"Class {}:\".format(i) for i in range(NUM_CLASSES)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kjr1bsqmLDAc"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(5,5, figsize=(15,15))\n",
    "for i,data in enumerate(test[:25]):\n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "    model_out = model.predict([data])[0]\n",
    "\n",
    "    if np.argmax(model_out) == 1:\n",
    "        str_predicted='Dog'\n",
    "    else:\n",
    "        str_predicted='Cat'\n",
    "    ax[i//5, i%5].imshow(orig)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_title(\"Predicted:{}\".format(str_predicted))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEbz8p11LGrx"
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "img_list = []\n",
    "for img in tqdm(test):\n",
    "    img_data = img[0]\n",
    "    img_idx = img[1]\n",
    "    data = img_data.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "    predicted = model.predict([data])[0]\n",
    "    img_list.append(img_idx)\n",
    "    pred_list.append(predicted[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyNrpjGpvnJrkHL8LZKKQzZD",
   "gpuType": "V28",
   "provenance": [
    {
     "file_id": "1wZHRxIvKm5muVuyejdt7SmogIYA9po_B",
     "timestamp": 1739744770301
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
